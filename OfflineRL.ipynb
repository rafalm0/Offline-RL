{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9eb637",
   "metadata": {},
   "source": [
    "# Assignment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71864714",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c83e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "rnd = np.random.default_rng(112233)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26d85e",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Building Cart Pole Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372639be",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca93e65",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Building Q-learning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7ced53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qlearning:\n",
    "    def __init__(self, env, alpha=.85, gamma=.95, epsilon=.1, bins=10,penalty=250,lr_model=None):\n",
    "        self.a = alpha\n",
    "        self.g = gamma\n",
    "        self.e = epsilon\n",
    "        self.n_bins = bins\n",
    "        self.env = env\n",
    "        self.penalty = penalty\n",
    "        self.greedy=False\n",
    "        self.lr_model = lr_model\n",
    "        \n",
    "        # changing bounds into more compact values to speed up training (fewer bins needed for this accuracy):\n",
    "        self.env_space = [[3, -3],\n",
    "                          [6, -6],\n",
    "                          [0.300, -0.300],\n",
    "                          [5, -5]]\n",
    "\n",
    "        self.q = self.gen_table()\n",
    "        \n",
    "        return\n",
    "\n",
    "    def gen_table(self):\n",
    "        action_dim = self.env.action_space.n\n",
    "\n",
    "        table = np.random.uniform(low=-0.001, high=0.001, size=(self.n_bins, self.n_bins, self.n_bins, self.n_bins, action_dim))\n",
    "\n",
    "        self.q = table\n",
    "        return self.q\n",
    "\n",
    "    def update(self, reward, state, action, next_state):\n",
    "        a, b, c, d, e = self.get_s(state, action)\n",
    "        a_, b_, c_, d_ = self.get_s(next_state)\n",
    "\n",
    "        self.q[a][b][c][d][e] = self.q[a][b][c][d][e] + self.a * (\n",
    "                reward + self.g * np.max(self.q[a_][b_][c_][d_]) - self.q[a][b][c][d][e])\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def offline_update(self, reward, state, action, next_state):\n",
    "        a, b, c, d, e = self.get_s(state, action)\n",
    "        a_, b_, c_, d_ = self.get_s(next_state)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def choose(self, state,imitation=False):\n",
    "\n",
    "        if imitation:\n",
    "            return int(self.lr_model.predict(np.array(state).reshape((1,-1)))[0])\n",
    "        \n",
    "        if (rnd.random() < self.e) and (self.greedy):\n",
    "            # random sampling\n",
    "            chosen = rnd.choice(list(range(self.env.action_space.n)))\n",
    "        else:\n",
    "            # greedy choice\n",
    "            table = self.q\n",
    "            for miniState in self.get_s(state):\n",
    "                table = table[miniState]\n",
    "\n",
    "            chosen = np.argmax(table)\n",
    "        return chosen\n",
    "    \n",
    "    def get_max(self,table,state):\n",
    "        for miniState in self.get_s(state):\n",
    "                table = table[miniState]\n",
    "\n",
    "        chosen = np.argmax(table)\n",
    "        return table[chosen], chosen\n",
    "\n",
    "    def get_s(self, state, action=None):\n",
    "        indexes = []\n",
    "        for i, feature in enumerate(state):\n",
    "            max_value = self.env_space[i][0]\n",
    "            min_value = self.env_space[i][1]\n",
    "\n",
    "            if (feature > max_value) or (feature < min_value):\n",
    "                raise ValueError(\n",
    "                    f\"Feature out of bounds for feature{str(i)} on bins : {str(feature)}  |min : {str(min_value)} - \"\n",
    "                    f\"max :{str(max_value)}|\")\n",
    "            window_size = (max_value - min_value) / self.n_bins\n",
    "            bin_loc = (feature - min_value) // window_size\n",
    "            indexes.append(int(bin_loc))\n",
    "\n",
    "        if action is None:\n",
    "            return indexes\n",
    "        else:\n",
    "            return indexes + [action]\n",
    "        \n",
    "\n",
    "    def episode(self,imitation=False):\n",
    "        state = self.env.reset()[0]\n",
    "        ended = False\n",
    "        ep_reward = 0\n",
    "        ep_history = []\n",
    "\n",
    "        while not ended:\n",
    "\n",
    "            action = self.choose(state,imitation=imitation)\n",
    "\n",
    "            # take A from S and get S'\n",
    "            new_state, reward, ended, time_limit, prob = env.step(action)\n",
    "\n",
    "            if ended:\n",
    "                reward -= self.penalty\n",
    "\n",
    "            self.update(reward, state, action, new_state)\n",
    "            \n",
    "            \n",
    "            ep_history.append(np.array([x for x in state] + [action] +[y for y in new_state] + [reward]))\n",
    "\n",
    "            # S <- S'\n",
    "            state = new_state\n",
    "            ep_reward += reward\n",
    "            if time_limit:\n",
    "                break\n",
    "\n",
    "        return ep_reward,np.array(ep_history)\n",
    "    \n",
    "    def offline_train(self, data, k=10):\n",
    "        \n",
    "        weights = np.zeros((self.n_bins, self.n_bins, self.n_bins, self.n_bins, self.env.action_space.n))\n",
    "        \n",
    "        for epoch in range(k):\n",
    "            total_error = 0\n",
    "            for batch in np.array_split(data, 10):\n",
    "                \n",
    "                grad = np.zeros_like(weights)\n",
    "\n",
    "                for index, row in batch.iterrows():\n",
    "                    state = list(row[['s1','s2','s3','s4']])\n",
    "                    next_state = list(row[['ns1','ns2','ns3','ns4']])\n",
    "                    action = row['action']\n",
    "                    r = row['reward']\n",
    "\n",
    "                    Q_next = self.get_s(next_state) # get choices for the next state\n",
    "                    max_Q_next = np.max(Q_next)\n",
    "                    target = r + self.gamma * max_Q_next\n",
    "                    \n",
    "                    Q_predicted = self.get_s(state, action) # get the current value for the state with action\n",
    "                    # we want to approximate the next to the current one and then \n",
    "                    \n",
    "                    # calculating the squared error for  this data_point\n",
    "                    error = (Q_predicted - target)**2\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        return \n",
    "    \n",
    "    # train\n",
    "    def train(self, episode_n=1000, verbose=False,use_model=False):\n",
    "        run_results = []\n",
    "        for i, mode in enumerate(range(episode_n)):\n",
    "            if verbose and (len(run_results) > 1):\n",
    "                print(f\"\\n{i + 1}th Segment: {np.mean(run_results)} avg reward\", end='')\n",
    "            reward, history = self.episode()\n",
    "            run_results.append(reward)\n",
    "\n",
    "        return run_results\n",
    "    \n",
    "    def gen_data(self,episodes=500,imitation=False,reward_=False):\n",
    "        self.greedy = True\n",
    "        \n",
    "        history_results = []\n",
    "        reward_results = []\n",
    "        for i in range(episodes):\n",
    "            reward, history =  self.episode(imitation=imitation)\n",
    "            for ep in history:\n",
    "                history_results.append(ep)\n",
    "            reward_results.append(reward)\n",
    "        \n",
    "        self.greedy = False\n",
    "        if reward_:\n",
    "            return reward_results, history_results\n",
    "        else:\n",
    "            return history_results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d80c",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Training the expert system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217fd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking best configurations from last assignment\n",
    "n_bins = 10\n",
    "\n",
    "epsilon = .15\n",
    "learning_rate = 1 / 4\n",
    "\n",
    "#setting one default rng for numpy \n",
    "rnd = np.random.default_rng(112233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ca6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expert model\n",
    "\n",
    "if not os.path.exists('Data'):\n",
    "    os.mkdir('Data')\n",
    "\n",
    "if not os.path.exists(f'Data/Data{str(500)}.csv'):\n",
    "    model = qlearning(env, alpha=learning_rate, epsilon=epsilon, bins=n_bins)\n",
    "    _ = model.train(episode_n=10000)\n",
    "\n",
    "# random model\n",
    "if not os.path.exists(f'Data_random/Data{str(500)}.csv'):\n",
    "    random_model = qlearning(env, alpha=learning_rate, epsilon=1, bins=n_bins)\n",
    "    _ = random_model.train(episode_n=10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc56eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Data for the normal greedy model\n",
    "\n",
    "for size in [100,250,500]:\n",
    "    if not os.path.exists(f'Data/Data{str(size)}.csv'):\n",
    "        data = np.array(model.gen_data(size))\n",
    "        df = pd.DataFrame(data, columns=['s1','s2','s3','s4', 'action', 'ns1','ns2','ns3','ns4', 'reward'])\n",
    "        df.to_csv(f'Data/Data{str(size)}.csv', index=False, sep=';', encoding='utf-8') # saving data\n",
    "    else:\n",
    "        df = pd.read_csv(f'Data/Data{str(size)}.csv', sep=';', encoding='utf-8')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283e6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Data for the random  model\n",
    "if not os.path.exists('Data_random'):\n",
    "    os.mkdir('Data_random')\n",
    "    \n",
    "for size in [100,250,500]:\n",
    "    if not os.path.exists(f'Data_random/Data{size}.csv'):\n",
    "        data = np.array(random_model.gen_data(size))\n",
    "        df_random = pd.DataFrame(data, columns=['s1','s2','s3','s4', 'action', 'ns1','ns2','ns3','ns4', 'reward'])\n",
    "        df_random.to_csv(f'Data_random/Data{size}.csv', index=False, sep=';', encoding='utf-8') # saving data\n",
    "    else:\n",
    "        df_random = pd.read_csv(f'Data_random/Data{size}.csv', sep=';', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e39bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>action</th>\n",
       "      <th>ns1</th>\n",
       "      <th>ns2</th>\n",
       "      <th>ns3</th>\n",
       "      <th>ns4</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009218</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009329</td>\n",
       "      <td>0.189145</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>-0.262565</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009329</td>\n",
       "      <td>0.189145</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>-0.262565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>-0.006374</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.039030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005546</td>\n",
       "      <td>-0.006374</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.039030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005673</td>\n",
       "      <td>0.188404</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>-0.246164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005673</td>\n",
       "      <td>0.188404</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>-0.246164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.007056</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0.054061</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.007056</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0.054061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.187784</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>-0.232469</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         s1        s2        s3        s4  action       ns1       ns2  \\\n",
       "0 -0.009218 -0.005560  0.028277  0.021064     1.0 -0.009329  0.189145   \n",
       "1 -0.009329  0.189145  0.028698 -0.262565     0.0 -0.005546 -0.006374   \n",
       "2 -0.005546 -0.006374  0.023447  0.039030     1.0 -0.005673  0.188404   \n",
       "3 -0.005673  0.188404  0.024228 -0.246164     0.0 -0.001905 -0.007056   \n",
       "4 -0.001905 -0.007056  0.019304  0.054061     1.0 -0.002046  0.187784   \n",
       "\n",
       "        ns3       ns4  reward  \n",
       "0  0.028698 -0.262565     1.0  \n",
       "1  0.023447  0.039030     1.0  \n",
       "2  0.024228 -0.246164     1.0  \n",
       "3  0.019304  0.054061     1.0  \n",
       "4  0.020386 -0.232469     1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data snippet\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80183e28",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Preparing data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2e0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [100, 250, 500]\n",
    "splits = [(1.0,.0), (.5,.5), (.0,1.0)]\n",
    "\n",
    "datasets = {100:{},250:{},500:{}}\n",
    "\n",
    "for size in sizes:\n",
    "    for split in splits:\n",
    "        x = df.sample(int(size*split[1]))\n",
    "        y = df_random.sample(int(size*split[0]))\n",
    "        datasets[size][split] = pd.concat([x,y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b8c47",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Imitation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52dee7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the logistic regression model for the immitation\n",
    "\n",
    "immitation_models = {100:{},250:{},500:{}}\n",
    "\n",
    "for size in sizes:\n",
    "    for split in splits:\n",
    "        data = datasets[size][split]\n",
    "        y = data['action']\n",
    "        X = data[['s1','s2','s3','s4']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "        lr = LogisticRegression(random_state=0,max_iter=500,multi_class='multinomial').fit(X_train.values,y_train.values)\n",
    "#         print(lr.score(X_test, y_test))\n",
    "\n",
    "        # now creating immitation model with the log regress \n",
    "        model = qlearning(env, alpha=learning_rate, epsilon=epsilon, bins=n_bins,lr_model=lr)\n",
    "        immitation_models[size][split] = model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbea70",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "### Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964f06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = immitation_models[500][(.0,1.0)]\n",
    "test_result = model.gen_data(episodes=100,imitation=True, reward_=True)[0]\n",
    "\n",
    "# compensating penalty for the purpose of visualization (normally all non-sucessfull would have an penalty)\n",
    "test_result = [x if x==500 else x+250 for x in test_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f86771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Runs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_result,bins=20)\n",
    "plt.xlabel(\"Total reward\")\n",
    "plt.ylabel(\"Runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be24cc",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Training fitted Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c24d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "\n",
    "K = 10\n",
    "learning_rates = [.25, .5]\n",
    "epsilon = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted model\n",
    "data = datasets[500][(.0,1.0)]\n",
    "model = qlearning(env)\n",
    "model.offline_train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4d9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a0f9b3",
   "metadata": {},
   "source": [
    "## Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0c367",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63644756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
