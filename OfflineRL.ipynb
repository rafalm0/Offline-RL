{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9eb637",
   "metadata": {},
   "source": [
    "# Assignment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71864714",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c83e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "rnd = np.random.default_rng(112233)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26d85e",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Building Cart Pole Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372639be",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca93e65",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Building Q-learning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7ced53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qlearning:\n",
    "    def __init__(self, env, alpha=.85, gamma=.95, epsilon=.1, bins=10):\n",
    "        self.a = alpha\n",
    "        self.g = gamma\n",
    "        self.q = self.gen_table(env, bins)\n",
    "        self.e = epsilon\n",
    "        self.n_bins = bins\n",
    "\n",
    "        # changing bounds into more compact values to speed up training (fewer bins needed for this accuracy):\n",
    "        self.env_space = [[3, -3],\n",
    "                          [6, -6],\n",
    "                          [0.300, -0.300],\n",
    "                          [5, -5]]\n",
    "\n",
    "        return\n",
    "\n",
    "    def gen_table(self, env, bins):\n",
    "        action_dim = env.action_space.n\n",
    "\n",
    "        table = np.random.uniform(low=-0.001, high=0.001, size=(bins, bins, bins, bins, action_dim))\n",
    "\n",
    "        self.q = table\n",
    "        return self.q\n",
    "\n",
    "    def update(self, reward, state, action, next_state):\n",
    "        a, b, c, d, e = self.get_s(state, action)\n",
    "        a_, b_, c_, d_ = self.get_s(next_state)\n",
    "\n",
    "        self.q[a][b][c][d][e] = self.q[a][b][c][d][e] + self.a * (\n",
    "                reward + self.g * np.max(self.q[a_][b_][c_][d_]) - self.q[a][b][c][d][e])\n",
    "\n",
    "        return None\n",
    "\n",
    "    def choose(self, env, state):\n",
    "\n",
    "        if rnd.random() < self.e:\n",
    "            # random sampling\n",
    "            chosen = rnd.choice(list(range(env.action_space.n)))\n",
    "        else:\n",
    "            # greedy choice\n",
    "            table = self.q\n",
    "            for miniState in self.get_s(state):\n",
    "                table = table[miniState]\n",
    "\n",
    "            chosen = np.argmax(table)\n",
    "        return chosen\n",
    "\n",
    "    def get_s(self, state, action=None):\n",
    "        indexes = []\n",
    "        for i, feature in enumerate(state):\n",
    "            max_value = self.env_space[i][0]\n",
    "            min_value = self.env_space[i][1]\n",
    "\n",
    "            if (feature > max_value) or (feature < min_value):\n",
    "                raise ValueError(\n",
    "                    f\"Feature out of bounds for feature{str(i)} on bins : {str(feature)}  |min : {str(min_value)} - \"\n",
    "                    f\"max :{str(max_value)}|\")\n",
    "            window_size = (max_value - min_value) / self.n_bins\n",
    "            bin_loc = (feature - min_value) // window_size\n",
    "            indexes.append(int(bin_loc))\n",
    "\n",
    "        if action is None:\n",
    "            return indexes\n",
    "        else:\n",
    "            return indexes + [action]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d80c",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Building the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c554a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining one episode\n",
    "def episode(model, env, render=False, penalty=250):\n",
    "    state = env.reset()[0]\n",
    "    if render:\n",
    "        env.render()\n",
    "    ended = False\n",
    "    ep_reward = 0\n",
    "\n",
    "    while not ended:\n",
    "\n",
    "        action = model.choose(env, state)\n",
    "\n",
    "        # take A from S and get S'\n",
    "        new_state, reward, ended, time_limit, prob = env.step(action)\n",
    "\n",
    "        if ended:\n",
    "            reward -= penalty\n",
    "\n",
    "        model.update(reward, state, action, new_state)\n",
    "\n",
    "        # S <- S'\n",
    "        state = new_state\n",
    "        ep_reward += reward\n",
    "        if time_limit:\n",
    "            break\n",
    "\n",
    "    if render:\n",
    "        env.close()\n",
    "    return ep_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f408765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining process for each of the runs\n",
    "def run(model, env, episode_n=1000, verbose=True, penalty=250):\n",
    "    run_results = []\n",
    "    for i, mode in enumerate(range(episode_n)):\n",
    "        if verbose and (len(run_results) > 1):\n",
    "            print(f\"\\n{i + 1}th Segment: {np.mean(run_results)} avg reward\", end='')\n",
    "        reward = episode(model, env, penalty=penalty)\n",
    "        run_results.append(reward)\n",
    "\n",
    "    return run_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80183e28",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "\n",
    "## Running the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa2e0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_bins = 10\n",
    "\n",
    "epsilons = [.075, .15, 0.2]\n",
    "learning_rates = [1 / 4, 1 / 8, 1 / 16]\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "#setting one default rng for numpy and 10 seeds for the 10 runs\n",
    "rnd = np.random.default_rng(112233)\n",
    "\n",
    "gym_seeds= [11,22,33,44,55,66,77,88,99,1010]\n",
    "\n",
    "training_size = 10\n",
    "testing_size = 1\n",
    "df_qlearn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bfe2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on |Epsilon: 0.075\t| Alpha: 0.25\n",
      "Training on |Epsilon: 0.15\t| Alpha: 0.25\n",
      "Training on |Epsilon: 0.2\t| Alpha: 0.25\n",
      "Training on |Epsilon: 0.075\t| Alpha: 0.125\n",
      "Training on |Epsilon: 0.15\t| Alpha: 0.125\n",
      "Training on |Epsilon: 0.2\t| Alpha: 0.125\n",
      "Training on |Epsilon: 0.075\t| Alpha: 0.0625\n",
      "Training on |Epsilon: 0.15\t| Alpha: 0.0625\n",
      "Training on |Epsilon: 0.2\t| Alpha: 0.0625\n"
     ]
    }
   ],
   "source": [
    "# Runing the training\n",
    "\n",
    "# generating one initial table state for every run\n",
    "common_table = np.random.uniform(low=-0.001, high=0.001, size=(n_bins, n_bins, n_bins, n_bins, 2))\n",
    "\n",
    "for alpha in learning_rates:\n",
    "    for epsilon in epsilons:\n",
    "        print(f'Training on |Epsilon: {str(epsilon)}\\t| Alpha: {str(alpha)}')\n",
    "\n",
    "        episode_results = []\n",
    "        \n",
    "        for i in range(n_runs):\n",
    "            env = gym.make('CartPole-v1')\n",
    "            env.action_space.seed(gym_seeds[i])\n",
    "            result_df = pd.DataFrame()\n",
    "            # creating model copies for each run\n",
    "            \n",
    "            n_model = qlearning(env, alpha=alpha, epsilon=epsilon, bins=n_bins)\n",
    "            n_model.q = common_table.copy()\n",
    "            result_df['ep_reward'] = run(n_model, env, verbose=False)\n",
    "            result_df['alpha'] = alpha\n",
    "            result_df['epsilon'] = epsilon\n",
    "            result_df['run'] = i\n",
    "            if df_qlearn is None:\n",
    "                df_qlearn = result_df.copy()\n",
    "            else:\n",
    "                df_qlearn = pd.concat([df_qlearn, result_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "152c7a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_reward</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-228.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-182.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-210.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-150.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-225.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-124.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-148.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ep_reward   alpha  epsilon  run\n",
       "0       -228.0  0.2500    0.075    0\n",
       "1       -182.0  0.2500    0.075    0\n",
       "2       -210.0  0.2500    0.075    0\n",
       "3       -150.0  0.2500    0.075    0\n",
       "4       -225.0  0.2500    0.075    0\n",
       "..         ...     ...      ...  ...\n",
       "995       40.0  0.0625    0.200    9\n",
       "996      -25.0  0.0625    0.200    9\n",
       "997     -124.0  0.0625    0.200    9\n",
       "998      -30.0  0.0625    0.200    9\n",
       "999     -148.0  0.0625    0.200    9\n",
       "\n",
       "[90000 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52dee7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataset if desired\n",
    "df_qlearn.to_csv('Qlearning.csv', index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "# loading dataset if already ran\n",
    "# df_qlearn = pd.read_csv('Qlearning.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a0f9b3",
   "metadata": {},
   "source": [
    "## Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd00b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63644756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
